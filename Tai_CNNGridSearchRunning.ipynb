{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39662c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#model selection\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Input, Add,Dropout, Dense, Activation, ZeroPadding2D, \\\n",
    "BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "#preprocess.\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#dl libraraies\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# specifically for cnn\n",
    "from keras.layers import Dropout, Flatten,Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# specifically for manipulating zipped images and getting numpy arrays of pixel values of images.\n",
    "import cv2                  \n",
    "import numpy as np  \n",
    "from tqdm import tqdm\n",
    "import os                   \n",
    "from random import shuffle  \n",
    "from zipfile import ZipFile\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import glob   \n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52289f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.curdir + \"/Flowers\"\n",
    "# Training data dir\n",
    "training_dir = os.curdir + '/Train'\n",
    "\n",
    "# Test data dir\n",
    "testing_dir = os.curdir + '/Test'\n",
    "\n",
    "# Ratio of training and testing data\n",
    "train_test_ratio = 0.8 \n",
    "\n",
    "def split_dataset_into_test_and_train_sets(all_data_dir = data_dir, training_data_dir = training_dir, \\\n",
    "                                           testing_data_dir=testing_dir, train_test_ratio = 0.8):\n",
    "    # Recreate testing and training directories\n",
    "    \n",
    "    if not os.path.exists(training_data_dir):\n",
    "            os.mkdir(training_data_dir)\n",
    "\n",
    "    if not os.path.exists(testing_data_dir):\n",
    "            os.mkdir(testing_data_dir)               \n",
    "    \n",
    "    num_training_files = 0\n",
    "    num_testing_files = 0\n",
    "\n",
    "\n",
    "    for subdir, dirs, files in os.walk(all_data_dir):\n",
    "        \n",
    "        category_name = os.path.basename(subdir)\n",
    "        \n",
    "        # print(category_name + \" vs \" + os.path.basename(all_data_dir))\n",
    "        if category_name == os.path.basename(all_data_dir):\n",
    "              continue\n",
    "\n",
    "        training_data_category_dir = training_data_dir + '/' + category_name\n",
    "        testing_data_category_dir = testing_data_dir + '/' + category_name\n",
    "        \n",
    "        # creating subdir for each sub category\n",
    "        if not os.path.exists(training_data_category_dir):\n",
    "            os.mkdir(training_data_category_dir)   \n",
    "\n",
    "        if not os.path.exists(testing_data_category_dir):\n",
    "            os.mkdir(testing_data_category_dir)\n",
    "            \n",
    "        file_list = glob.glob(os.path.join(subdir,'*.jpg'))\n",
    "\n",
    "        #print(os.path.join(all_data_dir, subdir))\n",
    "        print(str(category_name) + ' has ' + str(len(files)) + ' images') \n",
    "        random_set = np.random.permutation((file_list))\n",
    "        # copy percentage of data from each category to train and test directory\n",
    "        train_list = random_set[:round(len(random_set)*(train_test_ratio))] \n",
    "        test_list = random_set[-round(len(random_set)*(1-train_test_ratio)):]\n",
    "\n",
    "  \n",
    "\n",
    "        for lists in train_list : \n",
    "            shutil.copy(lists, training_data_dir + '/' + category_name + '/' )\n",
    "            num_training_files += 1\n",
    "  \n",
    "        for lists in test_list : \n",
    "            shutil.copy(lists, testing_data_dir + '/' + category_name + '/' )\n",
    "            num_testing_files += 1\n",
    "  \n",
    "\n",
    "    print(\"Processed \" + str(num_training_files) + \" training files.\")\n",
    "    print(\"Processed \" + str(num_testing_files) + \" testing files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7862c36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Babi has 931 images\n",
      "Calimerio has 353 images\n",
      "Chrysanthemum has 696 images\n",
      "Hydrangeas has 518 images\n",
      "Lisianthus has 969 images\n",
      "Pingpong has 360 images\n",
      "Rosy has 171 images\n",
      "Tana has 623 images\n",
      "Processed 3696 training files.\n",
      "Processed 925 testing files.\n"
     ]
    }
   ],
   "source": [
    "split_dataset_into_test_and_train_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f108b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3696 images belonging to 8 classes.\n",
      "Found 925 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Defining the imagedatagenerator for train and test image for pre-processing\n",
    "# We don't give horizonal_flip or other preprocessing for validation data generator\n",
    "\n",
    "image_size = 224\n",
    "batch_size = 64\n",
    "\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale = 1./255, #normalization\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.4,\n",
    "    height_shift_range = 0.4,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.1,\n",
    "    fill_mode = 'nearest',\n",
    "    horizontal_flip = True)\n",
    "valid_data_gen = ImageDataGenerator(rescale = 1./255)\n",
    "train_generator = train_data_gen.flow_from_directory(training_dir, (image_size,image_size), batch_size=batch_size, class_mode='categorical')\n",
    "valid_generator = valid_data_gen.flow_from_directory(testing_dir, (image_size,image_size), batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606d11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(dropout_rate, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (224,224,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(8, activation = \"softmax\"))\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy',metrics=['accuracy'])  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1189c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "lr_params = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "dropout_params = [0.2, 0.4]\n",
    "\n",
    "for lr in lr_params:\n",
    "    for dropout in dropout_params:\n",
    "        buf = create_cnn_model(dropout, lr)\n",
    "        history = buf.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n//batch_size,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=valid_generator.n//batch_size,\n",
    "        epochs=100,\n",
    "        verbose=1)\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend(['train', 'test'])\n",
    "        plt.show()\n",
    "        models.append(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778721db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
